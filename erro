import json
from langchain_core.messages import HumanMessage
from typing import List, Literal, TypedDict, Annotated
import sys
from pathlib import Path
import operator
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate

sys.path.insert(0, str(Path(__file__).parent.absolute()))
from utils.config import llm, logger


# State Schema
class InputIntentAgentState(TypedDict):
    dialog: Annotated[List[str], operator.add]
    last_input: str
    status: Literal["complete", "incomplete"]
    final_problem_statement: str
    messages: Annotated[List[dict], operator.add]
    flow_type: str
    documentation: List[str]
    next_question: str
    thread_id: str
    source: str


# Strict output schema using Pydantic
class ProblemOutput(BaseModel):
    dialog: list[str] = Field(description="Conversation history including user inputs and system clarifications")
    final_problem_statement: str = Field(description="Structured summary of the cloud troubleshooting issue")
    status: Literal["complete", "incomplete", "out_of_scope"] = Field(description="Status of the interaction")
    next_question: str = Field(description="Next clarifying question if status=incomplete, else empty string")


parser = PydanticOutputParser(pydantic_object=ProblemOutput)


# Input Agent Definition
def run_input_intent_agent(state: dict) -> dict:
    logger.info("State received by InputAgent:", state)

    dialog = state.get("dialog", [])
    last_input = state.get("last_input", "")
    if len(dialog) > 10:
        dialog = dialog[-10:]

    # Full prompt preserved
    prompt = PromptTemplate(
        template="""
You are a helpful and intelligent assistant. Your primary role is to act as the initial point of contact, diligently collecting all essential details about a user's technical issue.

---

**Your Responsibilities:**

1. **Listen Actively:**
   - Pay close attention to the user's input to understand their problem.

2. **Gather Information:**
   - Collect details such as:
     - Cloud provider (AWS, GCP, Azure, etc.)
     - Service (Compute, Database, Network, etc.)
     - Region/Zone
     - Resource identifiers (VM name, DB instance ID, etc.)
     - Error messages
     - Steps already taken
     - User‚Äôs preferred method of troubleshooting

3. **Structured Problem Statement:**
   - Organize the collected details into a clear, structured summary.

4. **Detect Completeness:**
   - If you have all the necessary details, mark the status as `"complete"`.
   - If details are missing, mark it as `"incomplete"` and ask a specific follow-up question.
   - If the issue is unrelated to cloud or IT operations, mark it as `"out_of_scope"`.

---

**Output Format:**

{format_instructions}

---

**Dialog so far:**
{dialog}

**New input from user:**
{last_input}

---

**Important Rules:**
- Always respond with valid JSON only.
- When `status` = "incomplete", you MUST provide a useful `next_question`.
- When `status` = "complete", `next_question` MUST be "".
- When `status` = "out_of_scope", politely guide the user back to cloud/IT related issues.
""",
        input_variables=["dialog", "last_input"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )

    # Retry wrapper
    retries = 2
    for attempt in range(retries):
        try:
            response = llm.invoke([HumanMessage(content=prompt.format(dialog=dialog, last_input=last_input))])
            logger.info(f"üîé LLM raw output: {response}")
            parsed: ProblemOutput = parser.invoke(response.content)

            # Append messages
            dialog.append({"role": "user", "content": last_input})
            if parsed.status == "incomplete" and parsed.next_question:
                dialog.append({"role": "assistant", "content": parsed.next_question})

            return {
                "dialog": dialog,
                "final_problem_statement": parsed.final_problem_statement,
                "status": parsed.status,
                "next_question": parsed.next_question,
                "last_input": ""
            }

        except Exception as e:
            logger.error(f"‚ö†Ô∏è Failed to parse LLM response (attempt {attempt+1}): {str(e)}")
            if attempt == retries - 1:
                # fallback
                dialog.append({"role": "user", "content": last_input})
                return {
                    "dialog": dialog,
                    "final_problem_statement": "Unable to fully parse the problem, needs clarification.",
                    "status": "incomplete",
                    "next_question": "Could you clarify which environment (prod or non-prod) this error occurred in?",
                    "last_input": ""
                }
