import asyncio
import json
import operator
from typing import Annotated, List, TypedDict

from google.cloud import pubsub_v1
from langchain_core.messages import BaseMessage, HumanMessage
from langgraph.graph import START, END, StateGraph

# --- Configuration ---
# IMPORTANT: Replace with your actual Google Cloud Project ID
PROJECT_ID = "your-gcp-project-id"

# Pub/Sub Topic and Subscription Names
# Agent A will publish its results to AGENT_A_OUTPUT_TOPIC
AGENT_A_OUTPUT_TOPIC = "agent-a-output"
# The main subscriber will listen to AGENT_A_OUTPUT_TOPIC via this subscription
AGENT_A_OUTPUT_SUBSCRIPTION = "agent-a-output-subscription"

# Agent B might have its own input topic if it's completely decoupled
# For this example, Agent B is part of the same LangGraph that Agent A triggers
# However, you could imagine Agent B also listening to a *different* Pub/Sub topic
# if it were a separate service/LangGraph instance.
AGENT_B_TOPIC = "agent-b-topic" # Example: if Agent B were a separate service

# --- Pub/Sub Helper Classes ---

class AsyncPubSubPublisher:
    """
    Asynchronous client for publishing messages to Google Pub/Sub.
    """
    def __init__(self, project_id: str):
        self.project_id = project_id
        # Initialize the Pub/Sub PublisherClient.
        # This client is thread-safe and can be reused.
        self.publisher = pubsub_v1.PublisherClient()

    async def publish_message(self, topic_id: str, data: bytes, **attributes):
        """
        Publishes a message to the specified Pub/Sub topic.
        Args:
            topic_id: The ID of the Pub/Sub topic.
            data: The message payload as bytes.
            attributes: Optional key-value attributes for the message.
        """
        topic_path = self.publisher.topic_path(self.project_id, topic_id)
        # The .publish() method returns a Future object.
        future = self.publisher.publish(topic_path, data, **attributes)

        try:
            # Await the result of the future in a separate thread
            # to avoid blocking the asyncio event loop while waiting for Pub/Sub ACK.
            await asyncio.to_thread(future.result)
            print(f"[{topic_id}] Published message. Message ID: {future.result()}")
        except Exception as e:
            print(f"[{topic_id}] Failed to publish message: {e}")
            raise # Re-raise to signal failure

class AsyncPubSubSubscriber:
    """
    Asynchronous client for subscribing to messages from Google Pub/Sub.
    Handles message reception and dispatches to a callback function.
    """
    def __init__(self, project_id: str, subscription_id: str, callback_fn):
        self.project_id = project_id
        self.subscription_id = subscription_id
        self.subscriber = pubsub_v1.SubscriberClient()
        self.subscription_path = self.subscriber.subscription_path(self.project_id, self.subscription_id)
        self.callback_fn = callback_fn
        self.streaming_pull_future = None

    def _message_callback(self, message: pubsub_v1.subscriber.message.Message):
        """
        Internal callback for Pub/Sub messages.
        This runs in a separate thread managed by the Pub/Sub client.
        It dispatches the message to the user-defined async callback on the main event loop.
        """
        loop = asyncio.get_event_loop()
        try:
            # Schedule the user-defined async callback as a task on the main event loop.
            loop.call_soon_threadsafe(
                lambda: asyncio.create_task(
                    self.callback_fn(message.data.decode('utf-8'), dict(message.attributes))
                )
            )
            message.ack() # Acknowledge the message once it's scheduled for processing
        except Exception as e:
            print(f"Error in _message_callback (message not acknowledged): {e}")
            # Consider nack() or specific error handling if message processing failed here
            # message.nack()

    async def start_listening(self):
        """Starts listening for messages on the configured subscription."""
        print(f"Listening for messages on {self.subscription_path}...")
        self.streaming_pull_future = self.subscriber.subscribe(
            self.subscription_path, callback=self._message_callback
        )
        try:
            # The .result() method of the future will block indefinitely in the background
            # until the subscriber is cancelled or an error occurs.
            # We wrap it in asyncio.to_thread to keep the main event loop non-blocked.
            await asyncio.to_thread(self.streaming_pull_future.result)
        except asyncio.CancelledError:
            print(f"Subscriber for {self.subscription_path} cancelled.")
        except Exception as e:
            print(f"Subscriber error for {self.subscription_path}: {e}")
        finally:
            self.streaming_pull_future.cancel()
            await asyncio.to_thread(self.subscriber.close)
            print(f"Subscriber for {self.subscription_path} stopped.")

    async def stop_listening(self):
        """Stops the Pub/Sub subscriber."""
        if self.streaming_pull_future:
            print(f"Stopping subscriber for {self.subscription_path}...")
            self.streaming_pull_future.cancel()
            # Give it a moment to shut down gracefully
            await asyncio.sleep(2) # Or await asyncio.to_thread(self.subscriber.close) directly if it's fast
            print("Subscriber shutdown initiated.")


# --- LangGraph Definition ---

class AgentState(TypedDict):
    """
    Represents the state of our graph.

    Attributes:
        messages: A list of messages exchanged between agents.
        workflow_step: Tracks the current step in the workflow.
        input_data: Initial data that triggered the workflow.
    """
    messages: Annotated[List[BaseMessage], operator.add]
    workflow_step: str
    input_data: dict

# Initialize Pub/Sub Publisher Client (can be global or passed around)
pubsub_publisher = AsyncPubSubPublisher(PROJECT_ID)

async def agent_a_node(state: AgentState):
    """
    Agent A processes the initial input and publishes its result to Pub/Sub.
    """
    print(f"\n--- Agent A ({state['workflow_step']}) ---")
    current_input = state['input_data'].get('content', 'No specific input.')
    print(f"Agent A received input: '{current_input}'")

    # Simulate some processing
    response_content = f"Agent A processed '{current_input}' and is ready for next step."
    new_message = HumanMessage(content=response_content, name="AgentA")

    # Publish the result to Pub/Sub for other services/agents to pick up
    message_payload = json.dumps({
        "workflow_id": "unique_workflow_id_123", # Important for tracking
        "from_agent": "AgentA",
        "processed_data": response_content,
        "next_step_hint": "proceed_to_agent_b"
    }).encode("utf-8")

    await pubsub_publisher.publish_message(AGENT_A_OUTPUT_TOPIC, message_payload)

    return {
        "messages": [new_message],
        "workflow_step": "agent_a_completed",
        "input_data": {} # Clear input_data or transform as needed
    }

async def agent_b_node(state: AgentState):
    """
    Agent B processes the input (likely from Pub/Sub via the callback)
    """
    print(f"\n--- Agent B ({state['workflow_step']}) ---")
    last_message = state['messages'][-1].content if state['messages'] else "No prior message."
    print(f"Agent B received state, last message: '{last_message}'")
    print(f"Agent B's internal input_data: {state['input_data']}")

    # Simulate some processing based on the state or new input_data
    processed_content = state['input_data'].get('processed_data', 'No specific data for B.')
    response_content = f"Agent B processed '{processed_content}' and completed its task."
    new_message = HumanMessage(content=response_content, name="AgentB")

    # This agent completes the workflow for this example
    return {
        "messages": [new_message],
        "workflow_step": "agent_b_completed"
    }

# --- Build LangGraph Workflow ---

workflow = StateGraph(AgentState)

# Add nodes for our agents
workflow.add_node("agent_a", agent_a_node)
workflow.add_node("agent_b", agent_b_node)

# Define edges (transitions)
# Start the workflow by going to Agent A
workflow.add_edge(START, "agent_a")

# After Agent A, in this direct LangGraph setup,
# we would transition to Agent B.
# However, for Pub/Sub async integration, Agent A publishing to Pub/Sub
# is the "end" of *its* immediate LangGraph run,
# and Pub/Sub triggers a *new* or resumed LangGraph run for Agent B.
# This setup simplifies the demo by assuming Agent B is the next step *within the same graph invocation*.

# For a truly decoupled system where Pub/Sub triggers a *new* graph run
# or a specific entry point of another graph instance:
# Agent A -> Pub/Sub -> (External System/Listener) -> (New LangGraph Invocation starting at Agent B)

# For this simplified consolidated example, we'll transition directly in the graph
# but Agent A's *primary role* is still to publish to Pub/Sub for demonstration.
workflow.add_edge("agent_a", "agent_b")

# Mark Agent B as the end of this specific workflow path
workflow.add_edge("agent_b", END)

# Compile the graph
app = workflow.compile()

# --- Pub/Sub Callback to Trigger/Resume LangGraph ---

async def pubsub_langgraph_callback(message_data: str, attributes: dict):
    """
    This function is called when a message is received from Pub/Sub.
    It acts as the entry point to trigger or resume a LangGraph workflow.
    """
    print(f"\n--- Pub/Sub Message Received ---")
    print(f"Message Data: {message_data}")
    print(f"Attributes: {attributes}")

    try:
        parsed_message = json.loads(message_data)
        from_agent = parsed_message.get("from_agent", "unknown")
        processed_data = parsed_message.get("processed_data", "")
        next_step_hint = parsed_message.get("next_step_hint", "")
        workflow_id = parsed_message.get("workflow_id", "default_workflow")

        # In a real application, you would use 'workflow_id' to load/retrieve
        # the existing LangGraph state for this specific workflow instance.
        # For this simple example, we'll create a new initial state based on the message.
        # This simulates the Pub/Sub message kick-starting the *next phase* of a workflow.

        # The 'input_data' will carry the payload received from Pub/Sub
        initial_state_for_graph = {
            "messages": [HumanMessage(content=f"Received from Pub/Sub: {processed_data}", name="PubSubListener")],
            "workflow_step": "pubsub_triggered",
            "input_data": parsed_message # Pass the full parsed message
        }

        print(f"Invoking LangGraph based on Pub/Sub message. Next hint: {next_step_hint}")

        # If the hint suggests 'proceed_to_agent_b', we can tell LangGraph to start there.
        # However, for a simple graph compiled like `app = workflow.compile()`,
        # `ainvoke` will always start from `START`.
        # For dynamic starting points based on external triggers, you might need:
        # 1. A more complex graph with conditional routing from START.
        # 2. To store and retrieve the graph's checkpoint (state) and then `app.ainvoke(checkpoint_state, config={"configurable": {"thread_id": workflow_id}})`
        #    if you want to *resume* an existing flow.

        # For this demo, let's simplify: the Pub/Sub message causes *this* graph
        # instance to run, effectively allowing the "agent_b" node to consume the `input_data`.
        final_state = await app.ainvoke(initial_state_for_graph)
        print("\n--- LangGraph Execution Finished (from Pub/Sub trigger) ---")
        print("Final LangGraph state:", final_state)

    except json.JSONDecodeError:
        print(f"Error: Could not parse message data as JSON: {message_data}")
    except Exception as e:
        print(f"An unexpected error occurred in Pub/Sub callback: {e}")

# --- Main Application Execution ---

async def main():
    """
    Main function to run the asynchronous LangGraph agents with Pub/Sub integration.
    """
    print("Starting asynchronous LangGraph agents with Pub/Sub...")

    # Initialize the Pub/Sub subscriber for Agent A's output topic
    subscriber = AsyncPubSubSubscriber(
        PROJECT_ID, AGENT_A_OUTPUT_SUBSCRIPTION, pubsub_langgraph_callback
    )

    # Start the subscriber in the background. This will continuously listen for messages.
    subscriber_task = asyncio.create_task(subscriber.start_listening())

    # --- Simulate an initial trigger for the workflow ---
    # This could be an API call, a scheduled job, user input, etc.
    initial_trigger_input = {
        "messages": [HumanMessage(content="Initial request to start workflow.")],
        "workflow_step": "initial_trigger",
        "input_data": {"initial_request": "Process this document"}
    }

    print("\n--- Initiating first LangGraph execution (Agent A) ---")
    # This will run the graph from START, through Agent A.
    # Agent A will then publish to Pub/Sub.
    try:
        initial_graph_run_result = await app.ainvoke(initial_trigger_input)
        print("\n--- Initial LangGraph execution finished (Agent A published to Pub/Sub) ---")
        print("Final state after initial run:", initial_graph_run_result)
    except Exception as e:
        print(f"Error during initial LangGraph run: {e}")

    # Keep the main event loop running indefinitely for the Pub/Sub subscriber
    # You might want a graceful shutdown mechanism in a real application.
    print("\nMain loop running. Waiting for Pub/Sub messages...")
    try:
        # Wait for the subscriber task to complete (e.g., if cancelled externally)
        await subscriber_task
    except asyncio.CancelledError:
        print("Main application loop cancelled.")
    finally:
        # Ensure the subscriber is stopped on shutdown
        await subscriber.stop_listening()
        print("Application shutting down.")

if __name__ == "__main__":
    # Ensure your Google Cloud credentials are set up
    # e.g., by running `gcloud auth application-default login` in your terminal
    # or by setting the GOOGLE_APPLICATION_CREDENTIALS environment variable.
    print("Setting up and running the async agents...")
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nApplication stopped by user (Ctrl+C).")
    except Exception as e:
        print(f"An error occurred during application startup/execution: {e}")
